# -*- coding: utf-8 -*-
"""dl_a2_letter_recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1M4OmiLzxFVemlyvND61zkKYoIGtBvnM-
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical

# Step 1: Load and preprocess the dataset
#url = "https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data"

# Step 1: Load and preprocess the dataset
df = pd.read_csv("letter-recognition.csv")
df

#df = pd.read_csv(url, header=None)
X = df.iloc[:, 1:].values
y = df.iloc[:, 0].values

# Encode labels into numerical values
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

# Normalize features
X = X / 15.0

# Split dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=25)

X_train = tf.convert_to_tensor(X_train)
X_test = tf.convert_to_tensor(X_test)
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# Step 2: Build the deep neural network model
model = Sequential()
model.add(Dense(64, input_shape=(16,), activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(26, activation='softmax'))

# Step 3: Compile and train the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(X_train, y_train, epochs=1, batch_size=32)

# Step 4: Evaluate the model
loss, accuracy = model.evaluate(X_test,y_test)
print("Test Loss:", loss)
print("Test Accuracy:", accuracy)

